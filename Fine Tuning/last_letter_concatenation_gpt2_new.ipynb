{"cells":[{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":333,"status":"ok","timestamp":1712792413859,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"9oJ7bL_aSJ1X"},"outputs":[],"source":["import json\n","\n","input_file = \"last_letter_concatenation_training.json\"  # Replace with the path to your JSONL file\n","output_file = \"output.txt\"  # Output file path\n","\n","with open(input_file, \"r\") as f:\n","    data = json.load(f)\n","\n","with open(output_file, \"w\") as f:\n","    for i in range(0,int(len(data)*0.7)):\n","        # json_data = json.loads(line.strip())\n","        prompt = data[i][\"prompt\"]\n","        completion = data[i][\"reasoning\"]\n","        answer = data[i][\"answer\"]\n","        f.write(f\"[Q] {prompt}\\n\")\n","        # f.write(\"[Q] \" + prompt + \"\\n\")\n","        f.write(f\"[A] {completion}--> {answer} END\\n\")\n","        # f.write(\"[A] \" + completion + \" --> \" + answer  \" END\\n\")\n","        f.write(\"\\n\")\n","\n","# with open(output_file, \"w\") as f:\n","#     for question in data:\n","#         # json_data = json.loads(line.strip())\n","#         prompt = question[\"prompt\"]\n","#         completion = question[\"reasoning\"]\n","#         answer = question[\"answer\"]\n","#         f.write(f\"[Q] {prompt}\\n\")\n","#         # f.write(\"[Q] \" + prompt + \"\\n\")\n","#         f.write(f\"[A] {completion}--> {answer} END\\n\")\n","#         # f.write(\"[A] \" + completion + \" --> \" + answer  \" END\\n\")\n","#         f.write(\"\\n\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1639,"status":"ok","timestamp":1712789614477,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"XK3EAtr7gBdd","outputId":"5e66e6f7-ee81-4672-e414-940ae9f9b4f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T44VzLMb-jlS"},"outputs":[],"source":["# data"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":434,"status":"ok","timestamp":1712792318248,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"H00kVH-JSauu"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import os"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":363,"status":"ok","timestamp":1712792416762,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"S7EXzRd9SzLV"},"outputs":[],"source":["def read_txt(file_path):\n","    with open(file_path, \"r\") as file:\n","        text = file.read()\n","    return text\n","\n","def read_documents_from_directory():\n","    combined_text = \"\"\n","    file_path = 'output.txt'\n","    combined_text += read_txt(file_path)\n","    return combined_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":545,"status":"ok","timestamp":1712792418646,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"9cfUaM5STR3e","outputId":"9e931bbe-2727-46de-ad1d-dd5b7866a597"},"outputs":[],"source":["# train_directory = '/content/drive/MyDrive/ColabNotebooks/data/chatbot_docs/training_data/q_and_a'\n","text_data = read_documents_from_directory()\n","text_data = re.sub(r'\\n+', '\\n', text_data).strip()  # Remove excess newline characters\n","text_data = re.sub(r\"END\", \"END\\n\",text_data)\n","text_data"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":517,"status":"ok","timestamp":1712792420790,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"WqKm6sEB_6Om"},"outputs":[],"source":["with open(output_file, 'w') as output_file:\n","    # output_file.write(\"\")\n","    output_file.write(text_data)\n","    output_file.close()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":14890,"status":"ok","timestamp":1712789643359,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"8uSEPMxHTeS_"},"outputs":[],"source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from transformers import Trainer, TrainingArguments"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":355,"status":"ok","timestamp":1712792424513,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"Skuk7BavTuQ-"},"outputs":[],"source":["def load_dataset(file_path, tokenizer, block_size = 128):\n","    dataset = TextDataset(\n","        tokenizer = tokenizer,\n","        file_path = file_path,\n","        block_size = block_size,\n","    )\n","    return dataset\n","\n","def load_data_collator(tokenizer, mlm = False):\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=tokenizer,\n","        mlm=mlm,\n","    )\n","    return data_collator"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":334,"status":"ok","timestamp":1712792427005,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"1wmcToLOT2b_"},"outputs":[],"source":["def train(train_file_path,model_name,\n","          output_dir,\n","          overwrite_output_dir,\n","          per_device_train_batch_size,\n","          num_train_epochs,\n","          save_steps):\n","  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","  train_dataset = load_dataset(train_file_path, tokenizer)\n","  data_collator = load_data_collator(tokenizer)\n","\n","  tokenizer.save_pretrained(output_dir)\n","\n","  model = GPT2LMHeadModel.from_pretrained(model_name)\n","  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","  model.to(device)\n","\n","  model.save_pretrained(output_dir)\n","\n","  training_args = TrainingArguments(\n","          output_dir=output_dir,\n","          overwrite_output_dir=overwrite_output_dir,\n","          per_device_train_batch_size=per_device_train_batch_size,\n","          num_train_epochs=num_train_epochs,\n","      )\n","\n","  trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          data_collator=data_collator,\n","          train_dataset=train_dataset,\n","  )\n","\n","  trainer.train()\n","  trainer.save_model()"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":314,"status":"ok","timestamp":1712792433838,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"H3km7RrAUCzQ"},"outputs":[],"source":["train_file_path = \"output.txt\"\n","model_name = 'gpt2'\n","output_dir = 'custom_q_and_a'\n","overwrite_output_dir = False\n","per_device_train_batch_size = 8\n","num_train_epochs = 50\n","save_steps = 20000"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76109,"status":"ok","timestamp":1712789519683,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"CDDVxzr9AXs6","outputId":"97e458b9-c502-4979-fc2b-fe202ca291a5"},"outputs":[],"source":["!pip install accelerate -U"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":342,"status":"ok","timestamp":1712789658463,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"yqhzmOvjqbYu"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":328,"status":"ok","timestamp":1712792437888,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"nlDBnBvZrPju","outputId":"838ce31c-e9b3-4a92-cc5d-41f8c7ae4f4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n","1\n","0\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","print(torch.cuda.device_count())\n","print(torch.cuda.current_device())"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":784987,"status":"ok","timestamp":1712793225782,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"6pCdvCq1UP0e","outputId":"53854510-c62a-4610-dd86-116b3e2918ad"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2500/2500 12:57, Epoch 50/50]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.679400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.211200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.118600</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.075200</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.054500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Checkpoint destination directory custom_q_and_a/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":397,"status":"ok","timestamp":1712793230785,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"hOVgVOsaVG20"},"outputs":[],"source":["from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer\n","def load_model(model_path):\n","    model = GPT2LMHeadModel.from_pretrained(model_path)\n","    return model\n","\n","\n","def load_tokenizer(tokenizer_path):\n","    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n","    return tokenizer\n","\n","def generate_text(model_path, sequence, max_length):\n","\n","    model = load_model(model_path)\n","    tokenizer = load_tokenizer(model_path)\n","    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n","    final_outputs = model.generate(\n","        ids,\n","        do_sample=True,\n","        max_length=max_length,\n","        pad_token_id=model.config.eos_token_id,\n","        top_k=50,\n","        top_p=0.95,\n","    )\n","    return tokenizer.decode(final_outputs[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5623,"status":"ok","timestamp":1712793242914,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"fUfE9bE3V5Ot","outputId":"4ceb73fe-ddc5-403b-b88c-65648acf8c68"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Q] Take the last letters of each words in \"Lucky Mireya Jj Kc\" and concatenate them.\n","[A] Sure, let's do that!\n","The last letters of each word in \"Lucky Mireya Jj Kc\" are:\n","* Lucky: y\n","* Mireya: a\n","* Jj: j\n","* Kc: c\n","So, the concatenation of the last letters is \"yajjc\".--> yajc END\n","\n","[Q\n"]}],"source":["model2_path = \"custom_q_and_a\"\n","sequence2 = '[Q] Take the last letters of each words in \"Lucky Mireya Jj Kc\" and concatenate them.'\n","max_len = 110\n","answer = generate_text(model2_path, sequence2, max_len)\n","print(answer)"]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":544,"status":"ok","timestamp":1712793246750,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"WKH2EfVDc4pc"},"outputs":[],"source":["f = open('last_letter_concatenation_training.json')\n","test_data = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C7AjMEVBZZVB"},"outputs":[],"source":["correct_predictions = 0\n","model2_path = \"custom_q_and_a\"\n","max_len = 130\n","for i in range(int(len(test_data)*0.7), len(test_data)):\n","\n","  new_prompt = test_data[i]['prompt']\n","  answer = generate_text(model2_path, \"[Q] \"+new_prompt, max_len)\n","  try:\n","    pred = str(answer.split(\"-->\")[1].split(\"END\")[0].strip())\n","    # print(answer.split(\"-->\")[1].split(\"END\")[0])\n","  except:\n","    pred = \"\"\n","    pass\n","  ans = test_data[i]['answer']\n","  if pred == ans:\n","    correct_predictions+= 1\n"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":365,"status":"ok","timestamp":1712795897036,"user":{"displayName":"Ravneet Kaur -","userId":"08486932357686958194"},"user_tz":420},"id":"mWj0xcXRlJw6","outputId":"5a0cae87-578b-4782-863c-8db4d57ff513"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy =  0.43859649122807015 %\n"]}],"source":["total_data_points = len(test_data) - int(len(test_data)*0.7)\n","print(\"Accuracy = \",(correct_predictions/total_data_points)*100, \"%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1BINvkGGnBz"},"outputs":[],"source":["# for i in range(int(len(test_data)*0.7), len(test_data)):\n","\n","#   new_prompt = test_data[i]['prompt']\n","#   answer = generate_text(model2_path, \"[Q] \"+new_prompt, max_len)\n","#   try:\n","#     pred = int(answer.split(\"-->\")[1].split(\"END\")[0].strip())\n","#     print(answer)\n","#     print(pred)\n","#     # break\n","#   except:\n","#     pred = -9999\n","#     pass\n","#   ans = test_data[i]['answer']\n","#   if '.' in test_data[i]['answer']:\n","#     pred=float(pred)\n","#     ans = float(ans)\n","#     print(ans)\n","#   else:\n","#     ans = int(ans)\n","#     print(ans)\n","\n","#   break\n","#   if pred == ans:\n","#     correct_predictions+= 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hChmcQrxGxQX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1z34Wz0k8d8nNeLif6h7CcIzciAEYVzWh","timestamp":1712723500821}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2 (tags/v3.12.2:6abddd9, Feb  6 2024, 21:26:36) [MSC v.1937 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"3fcbd7240ee8f908d933dc7f71e8c42a1a91163b70ede8dcff5146d4087436c7"}}},"nbformat":4,"nbformat_minor":0}
