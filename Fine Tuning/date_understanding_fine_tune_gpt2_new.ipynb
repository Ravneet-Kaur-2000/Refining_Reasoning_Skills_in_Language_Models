{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1712804312227,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"9oJ7bL_aSJ1X"},"outputs":[],"source":["import json\n","\n","input_file = \"date-understanding-training.json\"  # Replace with the path to your JSONL file\n","output_file = \"output.txt\"  # Output file path\n","\n","with open(input_file, \"r\") as f:\n","    data = json.load(f)\n","\n","x = len(data)*0.7\n","count = 0\n","with open(output_file, \"w\") as f:\n","    for question in data:\n","        if count>=x:\n","          break\n","        # json_data = json.loads(line.strip())\n","        prompt = question[\"prompt\"]\n","        completion = question[\"reasoning\"]\n","        answer = question[\"answer\"]\n","        f.write(f\"[Q] {prompt}\\n\")\n","        # f.write(\"[Q] \" + prompt + \"\\n\")\n","        f.write(f\"[A] {completion}. Answer \\\\boxed{{{answer}}}.--> {answer} END\\n\")\n","        # f.write(\"[A] \" + completion + \" --> \" + answer  \" END\\n\")\n","        f.write(\"\\n\")\n","        count+=1"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1712804312764,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"T44VzLMb-jlS"},"outputs":[],"source":["# data"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1712804312764,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"H00kVH-JSauu"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import os"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1712804312764,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"S7EXzRd9SzLV"},"outputs":[],"source":["def read_txt(file_path):\n","    with open(file_path, \"r\") as file:\n","        text = file.read()\n","    return text\n","\n","def read_documents_from_directory():\n","    combined_text = \"\"\n","    file_path = 'output.txt'\n","    combined_text += read_txt(file_path)\n","    return combined_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1712804312764,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"9cfUaM5STR3e","outputId":"8702d198-5712-4d7e-c2c3-88c0919622dd"},"outputs":[],"source":["# train_directory = '/content/drive/MyDrive/ColabNotebooks/data/chatbot_docs/training_data/q_and_a'\n","text_data = read_documents_from_directory()\n","text_data = re.sub(r'\\n+', '\\n', text_data).strip()  # Remove excess newline characters\n","text_data = re.sub(r\"END\", \"END\\n\",text_data)\n","text_data"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1712804312764,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"WqKm6sEB_6Om"},"outputs":[],"source":["with open(output_file, 'w') as output_file:\n","    # output_file.write(\"\")\n","    output_file.write(text_data)\n","    output_file.close()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":15496,"status":"ok","timestamp":1712804328257,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"8uSEPMxHTeS_"},"outputs":[],"source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from transformers import Trainer, TrainingArguments"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1712804328257,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"Skuk7BavTuQ-"},"outputs":[],"source":["def load_dataset(file_path, tokenizer, block_size = 128):\n","    dataset = TextDataset(\n","        tokenizer = tokenizer,\n","        file_path = file_path,\n","        block_size = block_size,\n","    )\n","    return dataset\n","\n","def load_data_collator(tokenizer, mlm = False):\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=tokenizer,\n","        mlm=mlm,\n","    )\n","    return data_collator"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1712804328257,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"1wmcToLOT2b_"},"outputs":[],"source":["def train(train_file_path,model_name,\n","          output_dir,\n","          overwrite_output_dir,\n","          per_device_train_batch_size,\n","          num_train_epochs,\n","          save_steps):\n","  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","  train_dataset = load_dataset(train_file_path, tokenizer)\n","  data_collator = load_data_collator(tokenizer)\n","\n","  tokenizer.save_pretrained(output_dir)\n","\n","  model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","  model.save_pretrained(output_dir)\n","\n","  training_args = TrainingArguments(\n","          output_dir=output_dir,\n","          overwrite_output_dir=overwrite_output_dir,\n","          per_device_train_batch_size=per_device_train_batch_size,\n","          num_train_epochs=num_train_epochs,\n","      )\n","\n","  trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          data_collator=data_collator,\n","          train_dataset=train_dataset,\n","  )\n","\n","  trainer.train()\n","  trainer.save_model()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1712804328257,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"H3km7RrAUCzQ"},"outputs":[],"source":["train_file_path = \"output.txt\"\n","model_name = 'gpt2'\n","output_dir = 'custom_q_and_a'\n","overwrite_output_dir = False\n","per_device_train_batch_size = 8\n","num_train_epochs = 50\n","save_steps = 50000"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13664,"status":"ok","timestamp":1712804341902,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"CDDVxzr9AXs6","outputId":"4fb9fc71-b7e3-4376-85e1-2840f894fb44"},"outputs":[],"source":["!pip install accelerate -U"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"elapsed":827015,"status":"ok","timestamp":1712805168912,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"6pCdvCq1UP0e","outputId":"029cbdc3-873f-4414-e94e-f4c75c65df33"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2550' max='2550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2550/2550 13:36, Epoch 50/50]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.724700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.364700</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.255700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.196000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.162800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1712805168912,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"hOVgVOsaVG20"},"outputs":[],"source":["from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer\n","def load_model(model_path):\n","    model = GPT2LMHeadModel.from_pretrained(model_path)\n","    return model\n","\n","\n","def load_tokenizer(tokenizer_path):\n","    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n","    return tokenizer\n","\n","def generate_text(model, tokenizer, sequence, max_length):\n","    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n","    final_outputs = model.generate(\n","        ids,\n","        do_sample=True,\n","        max_length=max_length,\n","        pad_token_id=model.config.eos_token_id,\n","        top_k=50,\n","        top_p=0.95,\n","    )\n","    return tokenizer.decode(final_outputs[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1712805168912,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"WKH2EfVDc4pc"},"outputs":[],"source":["f = open('date-understanding-training.json')\n","test_data = json.load(f)\n","\n","answers = []"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":1517397,"status":"ok","timestamp":1712806686308,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"iTq6hTXINE6L"},"outputs":[],"source":["correct_predictions = 0\n","model2_path = \"custom_q_and_a\"\n","model = load_model(model2_path)\n","tokenizer = load_tokenizer(model2_path)\n","model.eval()\n","max_len = 400\n","for i in range(int(len(test_data)*0.8), len(test_data)):\n","  new_prompt = test_data[i]['prompt']\n","  answer = generate_text(model, tokenizer, \"[Q] \"+new_prompt, max_len)\n","  answers.append(answer)\n","  try:\n","    pred = answer.split(\"-->\")[1].split(\"END\")[0].strip()\n","  except:\n","    pred = -9999\n","    pass\n","  ans = test_data[i]['answer']\n","  if pred == ans:\n","    correct_predictions+= 1\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1712806686308,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"mWj0xcXRlJw6","outputId":"2cce705e-b1fa-4f57-a0b6-5cb918446870"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy =  12.612612612612612 %\n"]}],"source":["total_data_points = len(test_data) - int(len(test_data)*0.7)\n","print(\"Accuracy = \" ,(correct_predictions/total_data_points)*100, \"%\")"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1712806686308,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"Sd4HGiYi0M1I"},"outputs":[],"source":["with open(\"answer.txt\",\"w\") as op:\n","  op.write(\"\\n\\n\".join(answers))\n","  op.close()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1z34Wz0k8d8nNeLif6h7CcIzciAEYVzWh","timestamp":1712723500821}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2 (tags/v3.12.2:6abddd9, Feb  6 2024, 21:26:36) [MSC v.1937 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"3fcbd7240ee8f908d933dc7f71e8c42a1a91163b70ede8dcff5146d4087436c7"}}},"nbformat":4,"nbformat_minor":0}
