{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1712719086982,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"9oJ7bL_aSJ1X"},"outputs":[],"source":["import json\n","\n","input_file = \"addsub_training.json\"  # Replace with the path to your JSONL file\n","output_file = \"output.txt\"  # Output file path\n","\n","with open(input_file, \"r\") as f:\n","    data = json.load(f)\n","\n","with open(output_file, \"w\") as f:\n","    for question in data:\n","        # json_data = json.loads(line.strip())\n","        prompt = question[\"prompt\"]\n","        completion = question[\"reasoning\"]\n","        answer = question[\"answer\"]\n","        f.write(f\"[Q] {prompt}\\n\")\n","        # f.write(\"[Q] \" + prompt + \"\\n\")\n","        f.write(f\"[A] {completion}--> {answer} END\\n\")\n","        # f.write(\"[A] \" + completion + \" --> \" + answer  \" END\\n\")\n","        f.write(\"\\n\")"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1712719086982,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"T44VzLMb-jlS"},"outputs":[],"source":["# data"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":361,"status":"ok","timestamp":1712719087342,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"H00kVH-JSauu"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import os"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1712719087342,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"S7EXzRd9SzLV"},"outputs":[],"source":["def read_txt(file_path):\n","    with open(file_path, \"r\") as file:\n","        text = file.read()\n","    return text\n","\n","def read_documents_from_directory():\n","    combined_text = \"\"\n","    file_path = 'output.txt'\n","    combined_text += read_txt(file_path)\n","    return combined_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1712719087342,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"9cfUaM5STR3e","outputId":"0f2c4100-02aa-4b77-e20d-5a549aed5d0b"},"outputs":[],"source":["# train_directory = '/content/drive/MyDrive/ColabNotebooks/data/chatbot_docs/training_data/q_and_a'\n","text_data = read_documents_from_directory()\n","text_data = re.sub(r'\\n+', '\\n', text_data).strip()  # Remove excess newline characters\n","text_data = re.sub(r\"END\", \"END\\n\",text_data)\n","text_data"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1712719087342,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"WqKm6sEB_6Om"},"outputs":[],"source":["with open(output_file, 'w') as output_file:\n","    # output_file.write(\"\")\n","    output_file.write(text_data)\n","    output_file.close()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12897,"status":"ok","timestamp":1712719100237,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"8uSEPMxHTeS_"},"outputs":[],"source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from transformers import Trainer, TrainingArguments"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1712719100237,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"Skuk7BavTuQ-"},"outputs":[],"source":["def load_dataset(file_path, tokenizer, block_size = 128):\n","    dataset = TextDataset(\n","        tokenizer = tokenizer,\n","        file_path = file_path,\n","        block_size = block_size,\n","    )\n","    return dataset\n","\n","def load_data_collator(tokenizer, mlm = False):\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=tokenizer,\n","        mlm=mlm,\n","    )\n","    return data_collator"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1712719100237,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"1wmcToLOT2b_"},"outputs":[],"source":["def train(train_file_path,model_name,\n","          output_dir,\n","          overwrite_output_dir,\n","          per_device_train_batch_size,\n","          num_train_epochs,\n","          save_steps):\n","  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","  train_dataset = load_dataset(train_file_path, tokenizer)\n","  data_collator = load_data_collator(tokenizer)\n","\n","  tokenizer.save_pretrained(output_dir)\n","\n","  model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","  model.save_pretrained(output_dir)\n","\n","  training_args = TrainingArguments(\n","          output_dir=output_dir,\n","          overwrite_output_dir=overwrite_output_dir,\n","          per_device_train_batch_size=per_device_train_batch_size,\n","          num_train_epochs=num_train_epochs,\n","      )\n","\n","  trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          data_collator=data_collator,\n","          train_dataset=train_dataset,\n","  )\n","\n","  trainer.train()\n","  trainer.save_model()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1712719100237,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"H3km7RrAUCzQ"},"outputs":[],"source":["train_file_path = \"output.txt\"\n","model_name = 'gpt2'\n","output_dir = 'custom_q_and_a'\n","overwrite_output_dir = False\n","per_device_train_batch_size = 8\n","num_train_epochs = 20\n","save_steps = 20000"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67739,"status":"ok","timestamp":1712719040747,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"CDDVxzr9AXs6","outputId":"bfe1ed48-4209-4691-c481-118c8d7f7efd"},"outputs":[],"source":["!pip install accelerate -U"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"executionInfo":{"elapsed":403474,"status":"ok","timestamp":1712719503708,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"6pCdvCq1UP0e","outputId":"f68cd5e4-9c82-4c9c-ce68-517b005a2264"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1200/1200 06:30, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.068700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.546900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":217,"status":"ok","timestamp":1712719511857,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"hOVgVOsaVG20"},"outputs":[],"source":["from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer\n","def load_model(model_path):\n","    model = GPT2LMHeadModel.from_pretrained(model_path)\n","    return model\n","\n","\n","def load_tokenizer(tokenizer_path):\n","    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n","    return tokenizer\n","\n","def generate_text(model_path, sequence, max_length):\n","\n","    model = load_model(model_path)\n","    tokenizer = load_tokenizer(model_path)\n","    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n","    final_outputs = model.generate(\n","        ids,\n","        do_sample=True,\n","        max_length=max_length,\n","        pad_token_id=model.config.eos_token_id,\n","        top_k=50,\n","        top_p=0.95,\n","    )\n","    return tokenizer.decode(final_outputs[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9917,"status":"ok","timestamp":1712719589546,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"fUfE9bE3V5Ot","outputId":"afee944d-d377-4b3a-9180-e1b87f427d4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Q] There are 37 short bushes and 30 tall trees currently in the park. Park workers will plant 20 short bushes today. How many short bushes will the park have when the workers are finished?\n","[A] Sure! Let's break down the problem step by step:\n","1. Current number of short bushes:\n","37 (currently in the park) = 13\n","2. Current height trees:\n","30 (currently in the park) = 11\n","3. Park workers will plant 20 short bushes today.\n","So, in total, the park will have 11 short bushes after today.--> 11 END\n","\n","[Q] There are 37 short bushes and 30 tall trees currently in the park. Park workers will plant 20 short bushes today\n"]}],"source":["model2_path = \"custom_q_and_a\"\n","sequence2 = \"[Q] There are 37 short bushes and 30 tall trees currently in the park . Park workers will plant 20 short bushes today . How many short bushes will the park have when the workers are finished ?\"\n","max_len = 150\n","answer = generate_text(model2_path, sequence2, max_len)\n","print(answer)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":613,"status":"ok","timestamp":1712719653223,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"WKH2EfVDc4pc"},"outputs":[],"source":["f = open('addsub_training.json')\n","test_data = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"executionInfo":{"elapsed":830158,"status":"error","timestamp":1712720583363,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"C7AjMEVBZZVB","outputId":"2d26f389-3920-454e-d7e6-f435128a1220"},"outputs":[],"source":["correct_predictions = 0\n","model2_path = \"custom_q_and_a\"\n","max_len = 150\n","for i in range(int(len(test_data)*0.7), len(test_data)):\n","\n","  new_prompt = test_data[i]['prompt']\n","  answer = generate_text(model2_path, \"[Q] \"+new_prompt, max_len)\n","  try:\n","    pred = int(answer.split(\"-->\")[1].split(\"END\")[0].strip())\n","  except:\n","    pred = -9999\n","    pass\n","  ans = test_data[i]['answer']\n","  if '.' in test_data[i]['answer']:\n","    pred=float(pred)\n","    ans = float(ans)\n","  else:\n","    ans = int(ans)\n","  if pred == ans:\n","    correct_predictions+= 1\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":537,"status":"ok","timestamp":1712720606827,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"mWj0xcXRlJw6","outputId":"c635c3f2-59b7-4b75-a7d2-a1d092f8a829"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy =  5.042016806722689 %\n"]}],"source":["total_data_points = len(test_data) - int(len(test_data)*0.7)\n","print(\"Accuracy = \",(correct_predictions/total_data_points)*100, \"%\")"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7236,"status":"ok","timestamp":1712720803573,"user":{"displayName":"Kaushal Binjola","userId":"14550819641295942542"},"user_tz":420},"id":"L1BINvkGGnBz","outputId":"2f0b4c2b-3623-4d8a-9f02-1e0d19d622e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Q] Sally had 39 baseball cards, and 9 were torn. Sara bought 24 of Sally's baseball cards. How many baseball cards does Sally have now?\n","[A] Sure! Let's break down the problem step by step:\n","1. Sally had 39 baseball cards.\n","2. Sara bought 24 of Sally's baseball cards.\n","So, let's add 24 to 39:\n","39 + 24 = 85\n","Therefore, Sally has 85 baseball cards now.--> 85 END\n","\n","[Q] There are 41 short trees and 32 tall trees currently in the park. Park workers had to cut down 32 short trees that were damaged. How many short trees will the park have when the workers are finished?\n","[A] Sure\n","85\n","15\n"]}],"source":["for i in range(int(len(test_data)*0.7), len(test_data)):\n","\n","  new_prompt = test_data[i]['prompt']\n","  answer = generate_text(model2_path, \"[Q] \"+new_prompt, max_len)\n","  try:\n","    pred = int(answer.split(\"-->\")[1].split(\"END\")[0].strip())\n","    print(answer)\n","    print(pred)\n","    # break\n","  except:\n","    pred = -9999\n","    pass\n","  ans = test_data[i]['answer']\n","  if '.' in test_data[i]['answer']:\n","    pred=float(pred)\n","    ans = float(ans)\n","    print(ans)\n","  else:\n","    ans = int(ans)\n","    print(ans)\n","\n","  break\n","  if pred == ans:\n","    correct_predictions+= 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hChmcQrxGxQX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1z34Wz0k8d8nNeLif6h7CcIzciAEYVzWh","timestamp":1712723500821}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2 (tags/v3.12.2:6abddd9, Feb  6 2024, 21:26:36) [MSC v.1937 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"3fcbd7240ee8f908d933dc7f71e8c42a1a91163b70ede8dcff5146d4087436c7"}}},"nbformat":4,"nbformat_minor":0}
