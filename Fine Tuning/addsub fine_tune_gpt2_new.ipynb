{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1717790451209,"user":{"displayName":"Saurabh Arun Yadgire","userId":"11034704596045637636"},"user_tz":420},"id":"oAhBcHpMYk6p","outputId":"90b2d4ee-b269-44cb-e62e-9e42152a1268"},"outputs":[],"source":["import shutil\n","\n","try:\n","  shutil.rmtree('custom_q_and_a')\n","except:\n","  print(\"Folder doesnt exist\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9oJ7bL_aSJ1X"},"outputs":[],"source":["import json\n","\n","input_file = \"addsub_training.json\"  # Replace with the path to your JSONL file\n","output_file = \"output.txt\"  # Output file path\n","\n","with open(input_file, \"r\") as f:\n","    data = json.load(f)\n","\n","x = len(data)*0.7\n","count = 0\n","with open(output_file, \"w\") as f:\n","    for question in data:\n","        if count>=x:\n","          break\n","        # json_data = json.loads(line.strip())\n","        prompt = question[\"prompt\"]\n","        completion = question[\"reasoning\"]\n","        answer = question[\"answer\"]\n","        f.write(f\"[Q] {prompt}\\n\")\n","        # f.write(\"[Q] \" + prompt + \"\\n\")\n","        f.write(f\"[A] {completion}. Answer \\\\boxed{{{answer}}}.--> {answer} END\\n\")\n","        # f.write(\"[A] \" + completion + \" --> \" + answer  \" END\\n\")\n","        f.write(\"\\n\")\n","        count+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H00kVH-JSauu"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S7EXzRd9SzLV"},"outputs":[],"source":["def read_txt(file_path):\n","    with open(file_path, \"r\") as file:\n","        text = file.read()\n","    return text\n","\n","def read_documents_from_directory():\n","    combined_text = \"\"\n","    file_path = 'output.txt'\n","    combined_text += read_txt(file_path)\n","    return combined_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1712792463270,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"9cfUaM5STR3e","outputId":"b91d7687-6305-4786-8902-894092e81afd"},"outputs":[],"source":["# train_directory = '/content/drive/MyDrive/ColabNotebooks/data/chatbot_docs/training_data/q_and_a'\n","text_data = read_documents_from_directory()\n","text_data = re.sub(r'\\n+', '\\n', text_data).strip()  # Remove excess newline characters\n","text_data = re.sub(r\"END\", \"END\\n\",text_data)\n","text_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WqKm6sEB_6Om"},"outputs":[],"source":["with open(output_file, 'w') as output_file:\n","    # output_file.write(\"\")\n","    output_file.write(text_data)\n","    output_file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8uSEPMxHTeS_"},"outputs":[],"source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from transformers import Trainer, TrainingArguments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Skuk7BavTuQ-"},"outputs":[],"source":["def load_dataset(file_path, tokenizer, block_size = 128):\n","    dataset = TextDataset(\n","        tokenizer = tokenizer,\n","        file_path = file_path,\n","        block_size = block_size,\n","    )\n","    return dataset\n","\n","def load_data_collator(tokenizer, mlm = False):\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=tokenizer,\n","        mlm=mlm,\n","    )\n","    return data_collator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wmcToLOT2b_"},"outputs":[],"source":["def train(train_file_path,model_name,\n","          output_dir,\n","          overwrite_output_dir,\n","          per_device_train_batch_size,\n","          num_train_epochs,\n","          save_steps):\n","  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","  train_dataset = load_dataset(train_file_path, tokenizer)\n","  data_collator = load_data_collator(tokenizer)\n","\n","  tokenizer.save_pretrained(output_dir)\n","\n","  model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","  model.save_pretrained(output_dir)\n","\n","  training_args = TrainingArguments(\n","          output_dir=output_dir,\n","          overwrite_output_dir=overwrite_output_dir,\n","          per_device_train_batch_size=per_device_train_batch_size,\n","          num_train_epochs=num_train_epochs,\n","      )\n","\n","  trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          data_collator=data_collator,\n","          train_dataset=train_dataset,\n","  )\n","\n","  trainer.train()\n","  trainer.save_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H3km7RrAUCzQ"},"outputs":[],"source":["train_file_path = \"output.txt\"\n","model_name = 'gpt2'\n","output_dir = 'custom_q_and_a'\n","overwrite_output_dir = False\n","per_device_train_batch_size = 8\n","num_train_epochs = 50\n","save_steps = 50000"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5831,"status":"ok","timestamp":1712792385039,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"CDDVxzr9AXs6","outputId":"4931be22-33f7-4305-ba3a-93de8e55909c"},"outputs":[],"source":["!pip install accelerate -U"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"elapsed":800079,"status":"ok","timestamp":1712793266819,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"6pCdvCq1UP0e","outputId":"341ac124-b2f2-4c35-ca9b-75eb90da002f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2550' max='2550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2550/2550 13:13, Epoch 50/50]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.942700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.358200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.182800</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.116000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.088900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hOVgVOsaVG20"},"outputs":[],"source":["from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer\n","def load_model(model_path):\n","    model = GPT2LMHeadModel.from_pretrained(model_path)\n","    return model\n","\n","\n","def load_tokenizer(tokenizer_path):\n","    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n","    return tokenizer\n","\n","def generate_text(model_path, sequence, max_length):\n","\n","    model = load_model(model_path)\n","    model.eval()\n","    tokenizer = load_tokenizer(model_path)\n","    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n","    final_outputs = model.generate(\n","        ids,\n","        do_sample=True,\n","        max_length=max_length,\n","        pad_token_id=model.config.eos_token_id,\n","        top_k=50,\n","        top_p=0.95,\n","    )\n","    return tokenizer.decode(final_outputs[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10326,"status":"ok","timestamp":1712793277142,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"fUfE9bE3V5Ot","outputId":"6eaaeec4-0fad-463d-bb36-0be239128177"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Q] There are 37 short bushes and 30 tall trees currently in the park. Park workers will plant 20 short bushes today. How many short bushes will the park have when the workers are finished?\n","[A] Sure! Let's break down the problem step by step:\n","1. Currently, there are 37 short bushes and 30 tall trees in the park, for a total of 85 trees.\n","2. Today, park workers will plant 20 short bushes.\n","3. To find out how many short bushes the park will have after the workers are finished, we need to add the number of short bushes being planted (35) to the current number of short bushes (87):\n","87 + 20 = 98\n","So, after the workers are finished, there will be 98 short bushes in the park.\n","Is that correct?. Answer: \\boxed{98}.--> 98 END\n","\n","[Q] There are currently 37 short bushes and 30 tall trees in the park.\n"]}],"source":["model2_path = \"custom_q_and_a\"\n","sequence2 = \"[Q] There are 37 short bushes and 30 tall trees currently in the park . Park workers will plant 20 short bushes today . How many short bushes will the park have when the workers are finished ?\"\n","max_len = 200\n","answer = generate_text(model2_path, sequence2, max_len)\n","print(answer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WKH2EfVDc4pc"},"outputs":[],"source":["f = open('addsub_training.json')\n","test_data = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C7AjMEVBZZVB"},"outputs":[],"source":["correct_predictions = 0\n","model2_path = \"custom_q_and_a\"\n","max_len = 200\n","for i in range(int(len(test_data)*0.7), len(test_data)):\n","\n","  new_prompt = test_data[i]['prompt']\n","  answer = generate_text(model2_path, \"[Q] \"+new_prompt, max_len)\n","  try:\n","    pred = int(answer.split(\"-->\")[1].split(\"END\")[0].strip())\n","  except:\n","    pred = -9999\n","    pass\n","  ans = test_data[i]['answer']\n","  if '.' in test_data[i]['answer']:\n","    pred=float(pred)\n","    ans = float(ans)\n","  else:\n","    ans = int(ans)\n","  if pred == ans:\n","    correct_predictions+= 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1712794488320,"user":{"displayName":"Kaushal Ganesh Binjola","userId":"06110090477420139849"},"user_tz":420},"id":"Sd4HGiYi0M1I","outputId":"9c0370f1-c9a1-4fd9-abc6-2931293c8e71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy =  12.605042016806722 %\n"]}],"source":["total_data_points = len(test_data) - int(len(test_data)*0.7)\n","print(\"Accuracy = \",(correct_predictions/total_data_points)*100, \"%\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1z34Wz0k8d8nNeLif6h7CcIzciAEYVzWh","timestamp":1712723500821}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2 (tags/v3.12.2:6abddd9, Feb  6 2024, 21:26:36) [MSC v.1937 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"3fcbd7240ee8f908d933dc7f71e8c42a1a91163b70ede8dcff5146d4087436c7"}}},"nbformat":4,"nbformat_minor":0}
